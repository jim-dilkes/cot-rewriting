{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "results_dirs = [\n",
    "    \".archive/results/stage_6_samples_final\",\n",
    "    # \".archive/results/llama_res\"\n",
    "    ]\n",
    "\n",
    "label_mapping_file = \"./results/experiment_label_mapping.tsv\"\n",
    "\n",
    "use_tasks = [\n",
    "        \"gsm8k\",\n",
    "        # \"tracking_shuffled_objects_three_objects\",\n",
    "        \"tracking_shuffled_objects_five_objects_multi\",\n",
    "        # \"coinflip_eight\",\n",
    "        \"prontoqa\",\n",
    "        \"logiqa-en\",\n",
    "        \"lsat-ar\",\n",
    "        \"navigate\",\n",
    "        \"aqua-rat\",\n",
    "        \"logical_deduction_five_objects_multi\"\n",
    "    ]\n",
    "\n",
    "task_name_mapping = {\n",
    "    \"gsm8k\": \"GSM8K\",\n",
    "    \"tracking_shuffled_objects/five_objects_multi\": \"Track5\",\n",
    "    \"coinflip_eight\": \"Coinflip\",\n",
    "    \"prontoqa\": \"ProntoQA\",\n",
    "    \"logiqa-en\": \"LogiQA\",\n",
    "    \"lsat-ar\": \"LSAT\",\n",
    "    \"navigate\": \"Nav\",\n",
    "    \"aqua-rat\": \"AQuA\",\n",
    "    \"logical_deduction/five_objects_multi\": \"Deduct5\"\n",
    "}\n",
    "\n",
    "use_dirs = [\n",
    "    # \"PromptWithAnswerExtraction\",\"SelfConsistency\"\n",
    "    \"PromptWithAnswerExtraction\",\"SelfConsistency\",\"SolveValidateRewrite\",\"SampleTree\"\n",
    "]\n",
    "# ]\n",
    "\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the nested JSON to make it suitable for a DataFrame\n",
    "def flatten(d, parent_key='', sep='_'):\n",
    "    items = {}\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if k == \"Models\":\n",
    "            items[k] = json.dumps(v)\n",
    "        elif isinstance(v, dict):\n",
    "            items |= flatten(v, new_key, sep=sep)\n",
    "        else:\n",
    "            items[new_key] = v\n",
    "    return items\n",
    "\n",
    "dfs = []\n",
    "for task in use_tasks:\n",
    "    for base_dir in use_dirs:\n",
    "        # Walk through base_dir and its subdirectories\n",
    "        for rd in results_dirs:\n",
    "            for root, _, files in os.walk(os.path.join(rd, task, base_dir)):\n",
    "                for file in files:\n",
    "                    # Check if the file is a .json file\n",
    "                    if file.endswith(\".json\"):\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        try:\n",
    "                            with open(file_path, \"r\") as f:\n",
    "                                data_dict = json.load(f)\n",
    "                                flat_data_dict = flatten(data_dict)\n",
    "                                tmp_df = pd.DataFrame([flat_data_dict])\n",
    "                                tmp_df['Models file'] = os.path.basename(root)\n",
    "                                dfs.append(tmp_df)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error reading {file_path}: {e}\")\n",
    "                            continue\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "# Move 'Models file' column to the front\n",
    "\n",
    "moddefs = df.pop('Models file')\n",
    "df.insert(0, 'Models file', moddefs)\n",
    "\n",
    "# Apply task name mapping\n",
    "df['Task'] = df['Task'].map(task_name_mapping)\n",
    "\n",
    "label_mapping = pd.read_csv(label_mapping_file, sep=\"\\t\")\n",
    "# Join on to df \n",
    "df = df.merge(label_mapping, left_on=['Models file', 'Prompt strategy'], right_on=['label', 'prompt_strategy'], how='left')\n",
    "df['Samples'] = pd.to_numeric(df['Samples'], errors='coerce').fillna(1).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = df.copy()\n",
    "# Flag if \"Models file\" string contains substring \"pattern\":\n",
    "# pivot_df['uses pattern'] = pivot_df['Models file'].str.contains(\"pattern\")\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt strategy','uses pattern','Models file'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Model Name','Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df= pivot_df[pivot_df['Experiment']!=\"Let's think\"]\n",
    "pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df.columns\n",
    "# del pivot_df['tracking_shuffled_objects/five_objects']\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 1)\n",
    "pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "pivot_df = df.copy()\n",
    "# Flag if \"Models file\" string contains substring \"pattern\":\n",
    "# pivot_df['uses pattern'] = pivot_df['Models file'].str.contains(\"pattern\")\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt strategy','uses pattern','Models file'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Model Name','Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df= pivot_df[pivot_df['Experiment']!=\"Let's think\"]\n",
    "pivot_df= pivot_df[pivot_df['Experiment']!=\"Let's think\"] \n",
    "# pivot_df= pivot_df[pivot_df['Prompt Strategy']!=\"Sample Tree\"]\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values=['Token counts_completion_per_example','Token counts_prompt_per_example'])\n",
    "pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment', 'Samples'],columns='Task',values=['Token counts_completion_per_example']).reset_index()\n",
    "# pivot_df = pivot_df.query('not (\"Prompt Strategy\" == \"Sample Path\" and \"Samples\" == 1)')\n",
    "mask = (pivot_df['Prompt Strategy'] == 'Sample Path') & (pivot_df['Samples'] == 1)\n",
    "pivot_df = pivot_df.loc[~mask]\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 1)\n",
    "pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "pivot_df = df.copy()\n",
    "# Flag if \"Models file\" string contains substring \"pattern\":\n",
    "# pivot_df['uses pattern'] = pivot_df['Models file'].str.contains(\"pattern\")\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt strategy','uses pattern','Models file'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Model Name','Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df= pivot_df[pivot_df['Experiment']!=\"Let's think\"]\n",
    "pivot_df= pivot_df[pivot_df['Experiment']!=\"Let's think\"] \n",
    "# pivot_df= pivot_df[pivot_df['Prompt Strategy']!=\"Sample Tree\"]\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values=['Token counts_completion_per_example','Token counts_prompt_per_example'])\n",
    "pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment','Samples'],columns='Task',values=['Token counts_completion_per_example'])\n",
    "order = ['GSM8K', 'LSAT', 'LogiQA', 'ProntoQA', 'Track5', 'AQuA', 'Deduct5', 'Nav']\n",
    "\n",
    "\n",
    "divider_row = pivot_df.loc[('Chain-of-Thought', 'Instruction',1)]\n",
    "\n",
    "# Divide every row by the contents of the divider_row\n",
    "pivot_df = pivot_df.divide(divider_row, axis=1)\n",
    "pivot_df['Row_Mean'] = pivot_df.mean(axis=1)\n",
    "\n",
    "pivot_df  = pivot_df.reset_index()\n",
    "mask = (pivot_df['Prompt Strategy'] == 'Sample Path') & (pivot_df['Samples'] == 1)\n",
    "pivot_df = pivot_df.loc[~mask]\n",
    "del pivot_df['Samples']\n",
    "pivot_df_prompt = pivot_df.copy()\n",
    "pivot_df_prompt.set_index(['Prompt Strategy', 'Experiment'], inplace=True)\n",
    "\n",
    "row_means_complete = pivot_df_prompt.mean(axis=1).reset_index()\n",
    "row_means_complete.columns = ['Prompt Strategy', 'Experiment', 'Mean']\n",
    "\n",
    "prompt_name_map = {'Chain-of-Thought': 'CoT','Self Consistency': 'SC', 'Rewriting': 'VR', 'Input-Output': 'IO', 'Sample Path': 'SP'}\n",
    "row_means_complete['Prompt Strategy'] = row_means_complete['Prompt Strategy'].map(prompt_name_map)\n",
    "row_means_complete['Combined'] = row_means_complete['Prompt Strategy'] + ' - ' + row_means_complete['Experiment']\n",
    "row_means_complete.loc[1, 'Combined'] = 'IO'\n",
    "\n",
    "# Reorder for the chart\n",
    "row_means_complete.iloc[0], row_means_complete.iloc[1] = row_means_complete.iloc[1].copy(), row_means_complete.iloc[0].copy()\n",
    "\n",
    "row_means_complete = pd.concat([row_means_complete.iloc[:2], row_means_complete.iloc[7:8], row_means_complete.iloc[2:7], row_means_complete.iloc[8:]])\n",
    "row_means_complete.reset_index(drop=True, inplace=True)\n",
    "row_means_complete.iloc[6], row_means_complete.iloc[7] = row_means_complete.iloc[7].copy(), row_means_complete.iloc[6].copy()\n",
    "row_means_complete.reset_index(drop=True, inplace=True)\n",
    "row_means_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 1)\n",
    "pd.set_option('display.float_format', '{:.1f}'.format)\n",
    "pivot_df = df.copy()\n",
    "# Flag if \"Models file\" string contains substring \"pattern\":\n",
    "# pivot_df['uses pattern'] = pivot_df['Models file'].str.contains(\"pattern\")\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt strategy','uses pattern','Models file'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Model Name','Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df= pivot_df[pivot_df['Experiment']!=\"Let's think\"]\n",
    "pivot_df= pivot_df[pivot_df['Experiment']!=\"Let's think\"] \n",
    "# pivot_df= pivot_df[pivot_df['Prompt Strategy']!=\"Sample Tree\"]\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values=['Token counts_completion_per_example','Token counts_prompt_per_example'])\n",
    "pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment','Samples'],columns='Task',values=['Token counts_prompt_per_example'])\n",
    "order = ['GSM8K', 'LSAT', 'LogiQA', 'ProntoQA', 'Track5', 'AQuA', 'Deduct5', 'Nav']\n",
    "\n",
    "# Let's assume you want to divide by the row at index 'some_index'\n",
    "divider_row = pivot_df.loc[('Chain-of-Thought', 'Instruction',1)]\n",
    "\n",
    "# Divide every row by the contents of the divider_row\n",
    "pivot_df = pivot_df.divide(divider_row, axis=1)\n",
    "pivot_df['Row_Mean'] = pivot_df.mean(axis=1)\n",
    "\n",
    "pivot_df  = pivot_df.reset_index()\n",
    "mask = (pivot_df['Prompt Strategy'] == 'Sample Path') & (pivot_df['Samples'] == 1)\n",
    "pivot_df = pivot_df.loc[~mask]\n",
    "del pivot_df['Samples']\n",
    "pivot_df_prompt = pivot_df.copy()\n",
    "pivot_df_prompt.set_index(['Prompt Strategy', 'Experiment'], inplace=True)\n",
    "\n",
    "row_means_prompt = pivot_df_prompt.mean(axis=1).reset_index()\n",
    "row_means_prompt.columns = ['Prompt Strategy', 'Experiment', 'Mean']\n",
    "\n",
    "prompt_name_map = {'Chain-of-Thought': 'CoT','Self Consistency': 'SC', 'Rewriting': 'VR', 'Input-Output': 'IO', 'Sample Path': 'SP'}\n",
    "row_means_prompt['Prompt Strategy'] = row_means_prompt['Prompt Strategy'].map(prompt_name_map)\n",
    "row_means_prompt['Combined'] = row_means_prompt['Prompt Strategy'] + ' - ' + row_means_prompt['Experiment']\n",
    "row_means_prompt.loc[1, 'Combined'] = 'IO'\n",
    "\n",
    "\n",
    "# Reorder for the chart\n",
    "row_means_prompt.iloc[0], row_means_prompt.iloc[1] = row_means_prompt.iloc[1].copy(), row_means_prompt.iloc[0].copy()\n",
    "\n",
    "row_means_prompt = pd.concat([row_means_prompt.iloc[:2], row_means_prompt.iloc[7:8], row_means_prompt.iloc[2:7], row_means_prompt.iloc[8:]])\n",
    "row_means_prompt.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "row_means_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "default_blue = sns.color_palette()[0]\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 12), sharex=True)\n",
    "\n",
    "palette = sns.color_palette(\"husl\", 9)\n",
    "c_io = 0\n",
    "c_cot = 1\n",
    "c_sc = 3\n",
    "c_rv = 6\n",
    "c_sp = 7\n",
    "colors = [\n",
    "    palette[c_io], palette[c_cot], palette[c_sc],  # 0, 1, 2\n",
    "    palette[c_rv],  palette[c_rv],  # 4, 5\n",
    "    palette[c_sp], palette[c_sp], palette[c_sp]   # 6, 7, 8\n",
    "]\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "legend_handles = [\n",
    "    mpatches.Patch(color=palette[c_io], label='Input-Output'),\n",
    "    mpatches.Patch(color=palette[c_cot], label='Chain-of-Thought'),\n",
    "    mpatches.Patch(color=palette[c_sc], label='Self-Consistency'),\n",
    "    mpatches.Patch(color=palette[c_rv], label='Rewriting'),\n",
    "    mpatches.Patch(color=palette[c_sp], label='Sampled Path')\n",
    "]\n",
    "\n",
    "# fig.legend(handles=legend_handles, bbox_to_anchor=(0.35, 0.98), facecolor=(1, 1, 1, 1))\n",
    "\n",
    "legend = fig.legend(handles=legend_handles, bbox_to_anchor=(0.35, 0.98))\n",
    "legend.get_frame().set_alpha(1)\n",
    "\n",
    "# Plot data for the first version\n",
    "sns.barplot(x='Combined', y='Mean', palette=colors, data=row_means_prompt, ax=axes[0])\n",
    "axes[0].axhline(y=1, linestyle='--', color='black')  # Dashed line at y=1\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_ylabel('Index vs CoT')\n",
    "axes[0].set_title('Prompt Tokens')\n",
    "\n",
    "# Plot data for the second version\n",
    "sns.barplot(x='Combined', y='Mean', palette=colors, data=row_means_complete, ax=axes[1])\n",
    "axes[1].axhline(y=1, linestyle='--', color='black')  # Dashed line at y=1\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=50)\n",
    "axes[1].set_ylabel('Index vs CoT')\n",
    "axes[1].set_title('Completion Tokens')\n",
    "\n",
    "plt.xlabel(None)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewrites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pivot_df = df.copy()\n",
    "# Flag if \"Models file\" string contains substring \"pattern\":\n",
    "# pivot_df['uses pattern'] = pivot_df['Models file'].str.contains(\"pattern\")\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt strategy','uses pattern','Models file'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Model Name','Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "pivot_df= pivot_df[pivot_df['Experiment']!=\"Let's think\"] \n",
    "# pivot_df= pivot_df[pivot_df['Prompt Strategy']!=\"Sample Tree\"]\n",
    "pivot_df= pivot_df[pivot_df['Prompt Strategy']!=\"Rewriting\"]\n",
    "# pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment','Temperature'],columns='Task',values='Accuracy')\n",
    "pivot_df  = pd.pivot_table(pivot_df, index=['Prompt Strategy','Experiment','Samples'],columns='Task',values='Accuracy')\n",
    "# Round all columns to three decimal places\n",
    "# df_rounded = df.round(3)\n",
    "\n",
    "# Convert 'Samples' column to integer\n",
    "multi_model = pd.pivot_table(df, index=['Model Name','Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "print(pivot_df.to_latex(float_format=\"%.3f\"))\n",
    "\n",
    "# pivot_df.columns\n",
    "# del pivot_df['tracking_shuffled_objects/five_objects']\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.pivot_table(df, index=['Model Name','Prompt Strategy','Experiment'],columns='Task',values='Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = pd.pivot_table(df, index=['Model Name','Prompt Strategy','Experiment'],columns='Task',values='Accuracy')\n",
    "multi_model = multi_model.to_latex(float_format=\"%.3f\")\n",
    "print(multi_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latex table of pivot_df\n",
    "latex_table = pivot_df.to_latex(float_format=\"%.3f\")\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
